{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Plant Disease recognition - Pattern Recognition Project\n",
        "\n",
        "**Team Details:**\n",
        "Hruday Chowdary Gurijala - S20210020278\n",
        "\n",
        "\n",
        "Jayaraj Chippada - S20210020263\n",
        "\n",
        "\n",
        "Sridhar Chunduri - S20210020266"
      ],
      "metadata": {
        "id": "HuhaCSRlDUXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Motivation\n",
        "\n",
        "As farmers and agriculture field are the important part of our life , farmers are the root level building blocks in the economy of any country . They work really heard for a whole season to grow a specific crop for survival of his family\n",
        "\n",
        "Sometimes these crops on which he dedicated his whole 3-6 months to nurture these crops got disease as result of which they can't sell their crops on the price he was expecting\n",
        "\n",
        "And He thinks if he knew these if he knew the plant disease before hand , he can use spefic pesticides and fertilizers to get over these disease\n",
        "\n",
        "What if we can use deep learning techniques to help famers to know about specific disease , so that they can be ready before harvestifying their crops"
      ],
      "metadata": {
        "id": "Hd5TvoupDx-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "We have 38 classes of plant disease images which contains 70295 images in training set and 17572 in valid set\n",
        "\n",
        "Each class contains average of 1700-1800 number of images to work upon\n",
        "\n",
        "Each image is of size= (256,256,3)"
      ],
      "metadata": {
        "id": "xAg4emh2EXNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!!! Using colab by Google is recommended or else install the libraries**\n",
        "\n",
        "**needed using the code cell below. !!! RUN EACH CODE CELL ONE AFTER THE OTHER.**"
      ],
      "metadata": {
        "id": "ygJfuSG_Egok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r libraries.txt\n",
        "# libraries.txt contains all libraries used and it can be found in the zip file."
      ],
      "metadata": {
        "id": "DxeQEoXnFTGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload the kaggle.json file in the zip file below**"
      ],
      "metadata": {
        "id": "CcYxloueFwtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUCdw0So1KY3"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
        "\n",
        "!unzip new-plant-diseases-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction using Histograms"
      ],
      "metadata": {
        "id": "55gZTETaGCrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "te29xSHP21hX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from skimage.feature import graycomatrix\n",
        "from skimage import io, color, feature\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pywt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bYda4BtG27wo"
      },
      "outputs": [],
      "source": [
        "def calculate_color_histogram(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert BGR to RGB (OpenCV uses BGR by default)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Calculate histograms for each color channel\n",
        "    hist_red = cv2.calcHist([image_rgb], [0], None, [256], [0, 256])\n",
        "    hist_green = cv2.calcHist([image_rgb], [1], None, [256], [0, 256])\n",
        "    hist_blue = cv2.calcHist([image_rgb], [2], None, [256], [0, 256])\n",
        "\n",
        "    return hist_red.flatten(), hist_green.flatten(), hist_blue.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aiHra6PP28Sy"
      },
      "outputs": [],
      "source": [
        "def extract_features(image_path):\n",
        "    # # Calculate color histogram\n",
        "    red_hist, green_hist, blue_hist = calculate_color_histogram(image_path)\n",
        "    all_features = np.concatenate((red_hist, green_hist, blue_hist))\n",
        "\n",
        "    return all_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MojtLJu3Bts"
      },
      "outputs": [],
      "source": [
        "# Load your dataset and extract features\n",
        "data_folder = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "BATCH_SIZE = 32\n",
        "classes = os.listdir(data_folder)\n",
        "X, y = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZbXLqhr3nWO"
      },
      "outputs": [],
      "source": [
        "# Inside the loop where you read images\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_folder, class_name)\n",
        "    images_in_class = os.listdir(class_path)\n",
        "\n",
        "    for i in range(0, len(images_in_class), BATCH_SIZE):\n",
        "        batch_images = images_in_class[i:i + BATCH_SIZE]\n",
        "        batch_features = []\n",
        "\n",
        "        for image_name in batch_images:\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Check if the image can be read\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None or image.size == 0:\n",
        "              print(f\"Error: Unable to read or empty image at {image_path}\")\n",
        "              continue  # Skip to the next iteration\n",
        "\n",
        "            features = extract_features(image_path)\n",
        "\n",
        "            print(features)\n",
        "            print(class_name)\n",
        "\n",
        "            if features is not None:\n",
        "                batch_features.append(features)\n",
        "\n",
        "        if batch_features:\n",
        "            # Concatenate features for the batch\n",
        "            batch_features = np.vstack(batch_features)\n",
        "\n",
        "            # Append features and labels to X and y\n",
        "            X.extend(batch_features)\n",
        "            y.extend([class_name] * len(batch_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXqt6-_C3rtY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWKLY2Vh6yKd"
      },
      "outputs": [],
      "source": [
        "# Load your dataset and extract features\n",
        "data_folder_valid = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "BATCH_SIZE = 32\n",
        "valid_classes = os.listdir(data_folder)\n",
        "x_valid, y_valid = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHXlBcFI7N_5"
      },
      "outputs": [],
      "source": [
        "for class_name in valid_classes:\n",
        "    class_path = os.path.join(data_folder_valid, class_name)\n",
        "    images_in_class = os.listdir(class_path)\n",
        "\n",
        "    for i in range(0, len(images_in_class), BATCH_SIZE):\n",
        "        batch_images = images_in_class[i:i + BATCH_SIZE]\n",
        "        batch_features = []\n",
        "\n",
        "        for image_name in batch_images:\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Check if the image can be read\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None or image.size == 0:\n",
        "              print(f\"Error: Unable to read or empty image at {image_path}\")\n",
        "              continue  # Skip to the next iteration\n",
        "\n",
        "            features = extract_features(image_path)\n",
        "\n",
        "            print(features)\n",
        "            print(class_name)\n",
        "\n",
        "            if features is not None:\n",
        "                batch_features.append(features)\n",
        "\n",
        "        if batch_features:\n",
        "            # Concatenate features for the batch\n",
        "            batch_features = np.vstack(batch_features)\n",
        "\n",
        "            # Append features and labels to X and y\n",
        "            x_valid.extend(batch_features)\n",
        "            y_valid.extend([class_name] * len(batch_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T-nCvPC7npn"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X_test = np.array(x_valid)\n",
        "y_valid = np.array(y_valid)\n",
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_test = label_encoder.fit_transform(y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN Classifier:**"
      ],
      "metadata": {
        "id": "RAcPc2qSG6v-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XrivRUt8-5L"
      },
      "outputs": [],
      "source": [
        "# Create a KNN classifier with k=3\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JATPLod59HFg"
      },
      "outputs": [],
      "source": [
        "# Train the classifier\n",
        "knn_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S_sWCsi9Mer"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vQw5ani9PYS"
      },
      "outputs": [],
      "source": [
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQbtqz9F0pDb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix# Calculate confusion matrix\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPVB8t7o08a5"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYMc2IGI1hKX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Model:**"
      ],
      "metadata": {
        "id": "_HkugwBCHEcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnedta2b-Qtm"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpKSVAIz915q"
      },
      "outputs": [],
      "source": [
        "# Create a logistic regression model for multi-class classification\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0sMXIcL96bV"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnF1kmpz9-4m"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc1ZRk9P-h6I"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Classification Report:\\n', classification_report_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xL4yalu2CsY"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOU8AWHc2Dd2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier:**"
      ],
      "metadata": {
        "id": "8UkfYdixHMoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqtnlFabDiLB"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIfXqb2KDld0"
      },
      "outputs": [],
      "source": [
        "# Create a Random Forest classifier for multiclass classification\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUOK7Y6BDoAf"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEzM8jrODqIp"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7bpehpNDtZJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Classification Report:\\n', classification_report_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmMKw12O2IX8"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31MmU6w_2Ho1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN:"
      ],
      "metadata": {
        "id": "R-8UNRDeHa3s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6kOprDZ57Mf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WHykIC35t6N"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert class labels to one-hot encoded format\n",
        "y_train_one_hot = to_categorical(y_train_encoded)\n",
        "y_test_one_hot = to_categorical(y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRa4sq8X5zee"
      },
      "outputs": [],
      "source": [
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly--MqE_5_E7"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOv0YPGF6A9k"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oALvrt8H6GJC"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the validation data\n",
        "eval_result = model.evaluate(X_test, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNJWIWev6Kx4"
      },
      "outputs": [],
      "source": [
        "## Display evaluation results\n",
        "print(f'Loss: {eval_result[0]}, Accuracy: {eval_result[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOsVasDR7tHK"
      },
      "outputs": [],
      "source": [
        "# Extract predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuSTuEf37u-r"
      },
      "outputs": [],
      "source": [
        "# Convert one-hot encoded true labels to class labels\n",
        "y_true = np.argmax(y_test_encoded)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Loss: {eval_result[0]}\")\n",
        "print(f\"Accuracy: {eval_result[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hceVM8bH6MuO"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTCa5reO6RVe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classsifier:**"
      ],
      "metadata": {
        "id": "9S5rMVeFHjuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ1HkiwN9jJr"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz2MiNqv9jov"
      },
      "outputs": [],
      "source": [
        "# Initialize the decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhVq41cN9mCL"
      },
      "outputs": [],
      "source": [
        "# Train the decision tree classifier\n",
        "dt_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR9RTHOb9n8s"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = dt_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vYepfCu9qRx"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFk3kIFn9w79"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7stnNe6h-JgV"
      },
      "outputs": [],
      "source": [
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Naive Bayes classifier:**"
      ],
      "metadata": {
        "id": "F2rDHW1SHurW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE-gbjTW-bVu"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIi4AJp9-rU0"
      },
      "outputs": [],
      "source": [
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLFVkIoI-tYb"
      },
      "outputs": [],
      "source": [
        "# Train the classifier\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVdWNaoy-vIj"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = nb_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGLmHsCp-xS0"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY5O27p_-zxU"
      },
      "outputs": [],
      "source": [
        "# Print the evaluation results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "altyyJ6B-73q"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUc-VYu5-1xq"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN:"
      ],
      "metadata": {
        "id": "ZTOb5cHsJK_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAaSUsLbyQEy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPdoaV2qyRUc"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "valid_dir = data_dir + \"/valid\"\n",
        "test_path  = os.path.join(\"/content/test\", \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AurX2eXbyUEC"
      },
      "outputs": [],
      "source": [
        "diseases = os.listdir(train_dir)\n",
        "nums = {}\n",
        "for disease in diseases:\n",
        "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv0_M0gPyY4I"
      },
      "outputs": [],
      "source": [
        "train_datagen= ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255.0,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.1)\n",
        "val_datagen= ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255.0,\n",
        "    validation_split=0.1)\n",
        "train= train_datagen.flow_from_directory(train_dir,batch_size=128,target_size=(210,210),color_mode='rgb',class_mode='categorical',seed=42)\n",
        "valid=val_datagen.flow_from_directory(valid_dir,batch_size=128,target_size=(210,210),color_mode='rgb',class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G46dfVV8yeP-"
      },
      "outputs": [],
      "source": [
        "classes=list(train.class_indices.keys())\n",
        "plt.figure(figsize=(20,20))\n",
        "for X_batch, y_batch in train:\n",
        "    for i in range(0,20):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.imshow(X_batch[i])\n",
        "        plt.title(classes[np.where(y_batch[i]==1)[0][0]])\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJfiQ37GyivI"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32,3,activation=\"relu\",padding=\"same\",input_shape=(210,210,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(256,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(38,activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MecWwYKymw-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit_generator(train,validation_data=valid,epochs = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA9ggsmFyqFC"
      },
      "outputs": [],
      "source": [
        "acc =history.history['accuracy']\n",
        "val_acc =history.history['val_accuracy']\n",
        "epochs = range(len(acc))\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs,acc,c=\"red\",label=\"Training\")\n",
        "plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFd2B6_SzeYH"
      },
      "outputs": [],
      "source": [
        "print(\"Train Accuracy  : {:.2f} %\".format(history.history['accuracy'][-1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting google drive to save models using .joblib"
      ],
      "metadata": {
        "id": "tGBqQkogJSDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUlAdXUJeuPB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajEvZR98eyB6"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model,'/content/drive/MyDrive/trained_models/model1.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL9CmDCp0YE7"
      },
      "source": [
        "**Pre-Trained Model-> Resnet50:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gMbo2zv01HW"
      },
      "outputs": [],
      "source": [
        "path='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "plt.figure(figsize=(70,70))\n",
        "count=0\n",
        "plant_names=[]\n",
        "total_images=0\n",
        "for i in os.listdir(path):\n",
        "  count+=1\n",
        "  plant_names.append(i)\n",
        "  plt.subplot(7,7,count)\n",
        "\n",
        "  images_path=os.listdir(path+\"/\"+i)\n",
        "  print(\"Number of images of \"+i+\":\",len(images_path),\"||\",end=\" \")\n",
        "  total_images+=len(images_path)\n",
        "\n",
        "  image_show=plt.imread(path+\"/\"+i+\"/\"+images_path[0])\n",
        "\n",
        "  plt.imshow(image_show)\n",
        "  plt.xlabel(i)\n",
        "\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "\n",
        "print(\"Total number of images we have\",total_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uuLnFQh1Grx"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzMQsXKV1LdV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbXGKqZO0lX3"
      },
      "outputs": [],
      "source": [
        "base_model_tf=ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=38)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeovETsv1AP5"
      },
      "outputs": [],
      "source": [
        "#Model building\n",
        "base_model_tf.trainable=False\n",
        "\n",
        "pt=Input(shape=(224,224,3))\n",
        "func=tensorflow.cast(pt,tensorflow.float32)\n",
        "x=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\n",
        "model_resnet=base_model_tf(x,training=False)\n",
        "model_resnet=GlobalAveragePooling2D()(model_resnet)\n",
        "model_resnet=Dense(128,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(64,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(38,activation='softmax')(model_resnet)\n",
        "\n",
        "\n",
        "model_main=Model(inputs=pt,outputs=model_resnet)\n",
        "model_main.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re6xlobU1Qv8"
      },
      "outputs": [],
      "source": [
        "#Image augmentation\n",
        "train_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n",
        "\n",
        "val_datagen=ImageDataGenerator()\n",
        "\n",
        "path_train='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "\n",
        "path_valid='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "\n",
        "train= train_datagen.flow_from_directory(directory=path_train,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical',seed=42)\n",
        "\n",
        "valid=val_datagen.flow_from_directory(directory=path_valid,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqBR1UTG1VYw"
      },
      "outputs": [],
      "source": [
        "#CallBacks\n",
        "es=EarlyStopping(monitor='val_accuracy',verbose=1,patience=7,mode='auto')\n",
        "mc=ModelCheckpoint(filepath='/content',monitor='val_accuracy',verbose=1,save_best_only=True)\n",
        "lr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tza2TPHP1uZn"
      },
      "outputs": [],
      "source": [
        "model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWTcyC3Q1x6c"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "model_main.fit(train,validation_data=valid,epochs=30,steps_per_epoch=200,verbose=1,callbacks=[mc,es,lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiPCSa3O10p0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(model_main.history.history['accuracy'],color='b',label='Training accuracy')\n",
        "plt.plot(model_main.history.history['val_accuracy'],color='r',label='Validation accsuracy')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"accuracy graph\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgW1S9nIfNGG"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save model using pickle\n",
        "with open('model_main.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "#saved model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f98BU9oKayoq"
      },
      "source": [
        "# Feature Extraction using Color Moments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GUeiLu_Ua48z"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from skimage.feature import graycomatrix\n",
        "from skimage import io, color, feature\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pywt\n",
        "from scipy.stats import skew, kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y7aPXThbbB7-"
      },
      "outputs": [],
      "source": [
        "def calculate_color_moments(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert BGR to RGB (OpenCV uses BGR by default)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # Calculate color moments for each channel\n",
        "    mean_values = np.mean(image_rgb, axis=(0, 1))\n",
        "    variances = np.var(image_rgb, axis=(0, 1))\n",
        "    skewness = skew(image_rgb.reshape(-1, 3), axis=0)\n",
        "    kurt = kurtosis(image_rgb.reshape(-1, 3), axis=0)\n",
        "    return np.concatenate([mean_values, variances, skewness, kurt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1CyjB6f7bQ1q"
      },
      "outputs": [],
      "source": [
        "def extract_features(image_path):\n",
        "    # # Color moments\n",
        "    color_moments = calculate_color_moments(image_path)\n",
        "    return color_moments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8naR9rgbbqD"
      },
      "outputs": [],
      "source": [
        "# Load your dataset and extract features\n",
        "data_folder = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "BATCH_SIZE = 32\n",
        "classes = os.listdir(data_folder)\n",
        "X, y = [], []\n",
        "\n",
        "# Inside the loop where you read images\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_folder, class_name)\n",
        "    images_in_class = os.listdir(class_path)\n",
        "\n",
        "    for i in range(0, len(images_in_class), BATCH_SIZE):\n",
        "        batch_images = images_in_class[i:i + BATCH_SIZE]\n",
        "        batch_features = []\n",
        "\n",
        "        for image_name in batch_images:\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Check if the image can be read\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None or image.size == 0:\n",
        "                print(f\"Error: Unable to read or empty image at {image_path}\")\n",
        "                continue  # Skip to the next iteration\n",
        "\n",
        "            features = extract_features(image_path)\n",
        "            print(features)\n",
        "            print(class_name)\n",
        "\n",
        "            if features is not None:\n",
        "                batch_features.append(features)\n",
        "\n",
        "        if batch_features:\n",
        "            # Concatenate features for the batch\n",
        "            batch_features = np.vstack(batch_features)\n",
        "            # Append features and labels to X and y\n",
        "            X.extend(batch_features)\n",
        "            y.extend([class_name] * len(batch_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjLmFlivcQzM"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X)\n",
        "y = np.array(y)\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y)\n",
        "# Load your dataset and extract features\n",
        "data_folder_valid = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "BATCH_SIZE = 32\n",
        "valid_classes = os.listdir(data_folder)\n",
        "x_valid, y_valid = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXLo7C5ZcZZE"
      },
      "outputs": [],
      "source": [
        "# Inside the loop where you read images\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(data_folder_valid, class_name)\n",
        "    images_in_class = os.listdir(class_path)\n",
        "\n",
        "    for i in range(0, len(images_in_class), BATCH_SIZE):\n",
        "        batch_images = images_in_class[i:i + BATCH_SIZE]\n",
        "        batch_features = []\n",
        "\n",
        "        for image_name in batch_images:\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Check if the image can be read\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None or image.size == 0:\n",
        "                print(f\"Error: Unable to read or empty image at {image_path}\")\n",
        "                continue  # Skip to the next iteration\n",
        "\n",
        "            features = extract_features(image_path)\n",
        "            print(features)\n",
        "            print(class_name)\n",
        "\n",
        "            if features is not None:\n",
        "                batch_features.append(features)\n",
        "\n",
        "        # This block should be outside the inner loop\n",
        "        if batch_features:\n",
        "            # Concatenate features for the batch\n",
        "            batch_features = np.vstack(batch_features)\n",
        "            # Append features and labels to X and y\n",
        "            x_valid.extend(batch_features)\n",
        "            y_valid.extend([class_name] * len(batch_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxvv8hZlc1Uu"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X_test = np.array(x_valid)\n",
        "y_valid = np.array(y_valid)\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_test = label_encoder.fit_transform(y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN:**"
      ],
      "metadata": {
        "id": "nubrf4n9KvfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500vYC7nM-W8"
      },
      "outputs": [],
      "source": [
        "# Create a KNN classifier with k=3\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQFo1oo5NC0r"
      },
      "outputs": [],
      "source": [
        "# Train the classifier\n",
        "knn_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qhjmyyGNLbC"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHxtUxIlNXG3"
      },
      "outputs": [],
      "source": [
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncEWs1_hNfUc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix# Calculate confusion matrix\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGlMy5C5NjJz"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvT_OI_ONn9i"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Model:**"
      ],
      "metadata": {
        "id": "SH6agrlNKzVJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU-rd3iLNswe"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAJLzfKENyfM"
      },
      "outputs": [],
      "source": [
        "# Create a logistic regression model for multi-class classification\n",
        "model_cmlr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB4Lg4VjN1c3"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training data\n",
        "model_cmlr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9GyLF7eODjI"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model_cmlr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR0ncDN3OERt"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Classification Report:\\n', classification_report_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32-DCiAdOIRe"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOPnTt0sOL9l"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier:**"
      ],
      "metadata": {
        "id": "wFw59jy6K4d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keVG4U4VOOUB"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laINc4b7ORup"
      },
      "outputs": [],
      "source": [
        "# Create a Random Forest classifier for multiclass classification\n",
        "model_cmrf = RandomForestClassifier(n_estimators=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJf-f8VVOVEF"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training data\n",
        "model_cmrf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttFR9rwgOhDx"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model_cmrf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLDxdojyOj-Y"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Classification Report:\\n', classification_report_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stXBAhjDOmId"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgWXbCt-OotV"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN:**"
      ],
      "metadata": {
        "id": "eSEuP1pvK89q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGWQM_sPPeWN"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRWceqkNPhYE"
      },
      "outputs": [],
      "source": [
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert class labels to one-hot encoded format\n",
        "y_train_one_hot = to_categorical(y_train_encoded)\n",
        "y_test_one_hot = to_categorical(y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcon631UPrY1"
      },
      "outputs": [],
      "source": [
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajeZsKzHPvpz"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGFtOKcDPwQx"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=90, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amws0vGMP9hk"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the validation data\n",
        "eval_result = model.evaluate(X_test, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZGjOymGQAek"
      },
      "outputs": [],
      "source": [
        "## Display evaluation results\n",
        "print(f'Loss: {eval_result[0]}, Accuracy: {eval_result[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vQFG-qbQBmi"
      },
      "outputs": [],
      "source": [
        "# Extract predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGDN5V5cQECV"
      },
      "outputs": [],
      "source": [
        "# Convert one-hot encoded true labels to class labels\n",
        "y_true = np.argmax(y_test_encoded)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Loss: {eval_result[0]}\")\n",
        "print(f\"Accuracy: {eval_result[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SzIVDZ2QGvi"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL1NHFkAQJAQ"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier:**"
      ],
      "metadata": {
        "id": "fl0z4sSgLAxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afylzJYFSVHd"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHPulbe9SXsZ"
      },
      "outputs": [],
      "source": [
        "# Initialize the decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQHvsXsgSZvx"
      },
      "outputs": [],
      "source": [
        "# Train the decision tree classifier\n",
        "dt_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_6aAxYwSiGQ"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = dt_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQiyUcdXSkwx"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZpfzJQSSpTQ"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LJzT_MCSqJX"
      },
      "outputs": [],
      "source": [
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Naive Bayes Classifier:**"
      ],
      "metadata": {
        "id": "QZrbm6GwLGuU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyFp4QELSsYo"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zul9JdkMT06v"
      },
      "outputs": [],
      "source": [
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uagwNUw7T20q"
      },
      "outputs": [],
      "source": [
        "# Train the classifier\n",
        "nb_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgV7Lt35T5Ik"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = nb_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MjnCr9cT7VY"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RJJvmuVT9gu"
      },
      "outputs": [],
      "source": [
        "# Print the evaluation results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKnH7hWpUCOD"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ8LNb6rUC0n"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(y_pred, y_test)\n",
        "# Plot the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=['y_probs', 'y_true'], yticklabels=['y_probs', 'y_true'])\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei77qEfbVAql"
      },
      "source": [
        "**resnet50(Pre-Trained Model):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xodDWOGrUSzw"
      },
      "outputs": [],
      "source": [
        "path='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "plt.figure(figsize=(70,70))\n",
        "count=0\n",
        "plant_names=[]\n",
        "total_images=0\n",
        "for i in os.listdir(path):\n",
        "  count+=1\n",
        "  plant_names.append(i)\n",
        "  plt.subplot(7,7,count)\n",
        "\n",
        "  images_path=os.listdir(path+\"/\"+i)\n",
        "  print(\"Number of images of \"+i+\":\",len(images_path),\"||\",end=\" \")\n",
        "  total_images+=len(images_path)\n",
        "\n",
        "  image_show=plt.imread(path+\"/\"+i+\"/\"+images_path[0])\n",
        "\n",
        "  plt.imshow(image_show)\n",
        "  plt.xlabel(i)\n",
        "\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "\n",
        "print(\"Total number of images we have\",total_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGMNtPMAVDqv"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVDpLOKNVFua"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4o4QMdwVH50"
      },
      "outputs": [],
      "source": [
        "base_model_tf=ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=38)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pJQPIQyVKfS"
      },
      "outputs": [],
      "source": [
        "#Model building\n",
        "base_model_tf.trainable=False\n",
        "\n",
        "pt=Input(shape=(224,224,3))\n",
        "func=tensorflow.cast(pt,tensorflow.float32)\n",
        "x=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\n",
        "model_resnet=base_model_tf(x,training=False)\n",
        "model_resnet=GlobalAveragePooling2D()(model_resnet)\n",
        "model_resnet=Dense(128,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(64,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(38,activation='softmax')(model_resnet)\n",
        "\n",
        "\n",
        "model_main=Model(inputs=pt,outputs=model_resnet)\n",
        "model_main.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s5jg4A1VODp"
      },
      "outputs": [],
      "source": [
        "#Image augmentation\n",
        "train_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n",
        "\n",
        "val_datagen=ImageDataGenerator()\n",
        "\n",
        "path_train='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "\n",
        "path_valid='/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "\n",
        "train= train_datagen.flow_from_directory(directory=path_train,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical',seed=42)\n",
        "\n",
        "valid=val_datagen.flow_from_directory(directory=path_valid,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjCeQhTGVRoP"
      },
      "outputs": [],
      "source": [
        "#CallBacks\n",
        "es=EarlyStopping(monitor='val_accuracy',verbose=1,patience=7,mode='auto')\n",
        "mc=ModelCheckpoint(filepath='/content',monitor='val_accuracy',verbose=1,save_best_only=True)\n",
        "lr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zV3q01BVUIo"
      },
      "outputs": [],
      "source": [
        "model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjWNXi5RVWaC"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "model_main.fit(train,validation_data=valid,epochs=6,steps_per_epoch=200,verbose=1,callbacks=[mc,es,lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF4lMNEpVYZf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(model_main.history.history['accuracy'],color='b',label='Training accuracy')\n",
        "plt.plot(model_main.history.history['val_accuracy'],color='r',label='Validation accsuracy')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"accuracy graph\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2UA-XtdmM3X"
      },
      "source": [
        "**CNN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTs_gNzamMav"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5JttzqMyniB"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "valid_dir = data_dir + \"/valid\"\n",
        "test_path  = os.path.join(\"/content/test\", \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jNsnEqIyph2"
      },
      "outputs": [],
      "source": [
        "diseases = os.listdir(train_dir)\n",
        "nums = {}\n",
        "for disease in diseases:\n",
        "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
        "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
        "img_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE82Av82ysF9"
      },
      "outputs": [],
      "source": [
        "train_datagen= ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255.0,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.1)\n",
        "val_datagen= ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        "    rescale=1/255.0,\n",
        "    validation_split=0.1)\n",
        "train= train_datagen.flow_from_directory(train_dir,batch_size=128,target_size=(210,210),color_mode='rgb',class_mode='categorical',seed=42)\n",
        "valid=val_datagen.flow_from_directory(valid_dir,batch_size=128,target_size=(210,210),color_mode='rgb',class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7wCk1zYyvBd"
      },
      "outputs": [],
      "source": [
        "classes=list(train.class_indices.keys())\n",
        "plt.figure(figsize=(20,20))\n",
        "for X_batch, y_batch in train:\n",
        "    for i in range(0,20):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.imshow(X_batch[i])\n",
        "        plt.title(classes[np.where(y_batch[i]==1)[0][0]])\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3LhGHo2yxJt"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32,3,activation=\"relu\",padding=\"same\",input_shape=(210,210,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(256,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(38,activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAKBrrVCyzwI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit_generator(train,validation_data=valid,epochs = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeO9iBqLy2o5"
      },
      "outputs": [],
      "source": [
        "acc =history.history['accuracy']\n",
        "val_acc =history.history['val_accuracy']\n",
        "epochs = range(len(acc))\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs,acc,c=\"red\",label=\"Training\")\n",
        "plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQqfW5GJy6V8"
      },
      "outputs": [],
      "source": [
        "print(\"Train Accuracy  : {:.2f} %\".format(history.history['accuracy'][-1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As In formed in the evaluation, the stats of the cnn model is compared to other models in the project report.The code for the cnn model can be found in zip file."
      ],
      "metadata": {
        "id": "wQ1QhV-6NwFu"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}